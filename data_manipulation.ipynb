{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189626, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>like_count</th>\n",
       "      <th>rt_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>language</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-21 03:29:07</td>\n",
       "      <td>New search &amp;amp; rescue work is in progress in...</td>\n",
       "      <td>['Hatay', 'earthquakes', 'Türkiye', 'TurkiyeQu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5697.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-21 03:29:04</td>\n",
       "      <td>Can't imagine those who still haven't recovere...</td>\n",
       "      <td>['Turkey', 'earthquake', 'turkeyearthquake2023...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-21 03:28:06</td>\n",
       "      <td>its a highkey sign for all of us to ponder ove...</td>\n",
       "      <td>['turkeyearthquake2023', 'earthquake', 'Syria']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-02-21 03:27:27</td>\n",
       "      <td>See how strong was the Earthquake of Feb 20, 2...</td>\n",
       "      <td>['Earthquake', 'Hatay', 'Turkey', 'turkeyearth...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21836.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-02-21 03:27:11</td>\n",
       "      <td>More difficult news today on top of struggles ...</td>\n",
       "      <td>['Türkiye', 'Syria', 'earthquake', 'Canadians']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                            content  \\\n",
       "1  2023-02-21 03:29:07  New search &amp; rescue work is in progress in...   \n",
       "2  2023-02-21 03:29:04  Can't imagine those who still haven't recovere...   \n",
       "3  2023-02-21 03:28:06  its a highkey sign for all of us to ponder ove...   \n",
       "5  2023-02-21 03:27:27  See how strong was the Earthquake of Feb 20, 2...   \n",
       "6  2023-02-21 03:27:11  More difficult news today on top of struggles ...   \n",
       "\n",
       "                                            hashtags  like_count  rt_count  \\\n",
       "1  ['Hatay', 'earthquakes', 'Türkiye', 'TurkiyeQu...         1.0       0.0   \n",
       "2  ['Turkey', 'earthquake', 'turkeyearthquake2023...         0.0       0.0   \n",
       "3    ['turkeyearthquake2023', 'earthquake', 'Syria']         0.0       0.0   \n",
       "5  ['Earthquake', 'Hatay', 'Turkey', 'turkeyearth...         0.0       0.0   \n",
       "6    ['Türkiye', 'Syria', 'earthquake', 'Canadians']         1.0       0.0   \n",
       "\n",
       "   followers_count language coordinates place  \n",
       "1           5697.0       en         NaN   NaN  \n",
       "2              1.0       en         NaN   NaN  \n",
       "3              3.0       en         NaN   NaN  \n",
       "5          21836.0       en         NaN   NaN  \n",
       "6            675.0       en         NaN   NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "full_data = pd.read_csv('./archive/tweets.csv', low_memory=False)\n",
    "\n",
    "only_english = full_data[full_data['language'] == 'en']\n",
    "\n",
    "# Remove the source and isVerified column\n",
    "\n",
    "only_english = only_english.drop(['source'], axis=1)\n",
    "only_english = only_english.drop(['isVerified'], axis=1)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # remove mentions\n",
    "    text = re.sub(r'#', '', text) # remove hashtags\n",
    "    text = re.sub(r'\\s+', ' ', text) # remove extra whitespace\n",
    "    return text\n",
    "\n",
    "only_english['content'] = only_english['content'].apply(clean_text)\n",
    "\n",
    "# Transform the date column to datetime format\n",
    "only_english['date'] = pd.to_datetime(only_english['date'])\n",
    "only_english['date'] = only_english['date'].dt.strftime('%Y-%m-%d %H:%M:%S') # stolen from main file\n",
    "\n",
    "\n",
    "# print the number of rows and columns\n",
    "print(only_english.shape)\n",
    "only_english.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geotext import GeoText\n",
    "\n",
    "def dest_text(text):\n",
    "    places = GeoText(text).cities\n",
    "    if places:\n",
    "        return places[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "only_english['city_mention'] = only_english['content'].apply(dest_text)\n",
    "only_english.dropna(subset=['city_mention'], inplace=True)\n",
    "\n",
    "only_english.head()\n",
    "\n",
    "only_english.to_csv('./archive/only_english.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Geocoding progress: 100%|██████████| 17942/17942 [2:29:31<00:00,  2.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tweets with coordinates: 17937\n",
      "Amount of tweets with distance: 348\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim #for geocoding\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./archive/only_english.csv\")\n",
    "\n",
    "# Create a new column with the distance from location after finding *km or *miles in text.\n",
    "data['distance'] = data['content'].apply(lambda x: re.findall(r'\\d+km|\\d+miles', x))\n",
    "\n",
    "# Extract the number from the distance column and convert it to float.\n",
    "data['distance'] = data['distance'].apply(lambda x: float(re.findall(r'\\d+', x[0])[0]) if len(x) > 0 else None)\n",
    "\n",
    "# Create a geolocator object with a custom user_agent\n",
    "geolocator = Nominatim(user_agent=\"my-custom-user-agent\")\n",
    "\n",
    "# Define a function to get the coordinates of a location\n",
    "def get_coordinates(row):\n",
    "    try:\n",
    "        # Use geolocator to get the location's coordinates\n",
    "        location = geolocator.geocode(row['city_mention'])\n",
    "        return pd.Series({'latitude': location.latitude, 'longitude': location.longitude})\n",
    "    except:\n",
    "        return pd.Series({'latitude': None, 'longitude': None})\n",
    "\n",
    "# Remove duplicate city names within the array\n",
    "seen_cities = set()\n",
    "data['city_mention'] = data['city_mention'].apply(lambda x: x if x not in seen_cities else None if None else seen_cities.add(x) or x)\n",
    "\n",
    "# Apply the get_coordinates function to the city column to create a new coordinates column\n",
    "tqdm.pandas(desc=\"Geocoding progress\")\n",
    "data[['latitude', 'longitude']] = data.progress_apply(lambda row: get_coordinates(row), axis=1)\n",
    "\n",
    "# Print the amount of tweets with location and distance.\n",
    "print(f\"Amount of tweets with coordinates: {len(data[data['latitude'].notnull()])}\")\n",
    "print(f\"Amount of tweets with distance: {len(data[data['distance'].notnull()])}\")\n",
    "\n",
    "# save the data to a new csv file called \"full_data.csv\"\n",
    "data.to_csv(\"./archive/english_data_with_locations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine files translated dataset 1 and 2 \n",
    "\n",
    "data1 = pd.read_csv(\"translated_dataset3.csv\")\n",
    "data2 = pd.read_csv(\"translated_dataset3_2.csv\")\n",
    "\n",
    "full_data = pd.concat([data1, data2], ignore_index=True)\n",
    "full_data.to_csv(\"full_data_with_english.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
